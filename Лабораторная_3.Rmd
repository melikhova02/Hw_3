---
title: "Лабораторная_3"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
  word_document: default
---

### Параметрические классификаторы для бинарной зависимой переменной (Y)

В данной задаче выполняются следующие пункты:   
 
* построение модели логистической регрессии;
* построение модели линейного дискриминантного анализа (LDA);
* построение модели квадратичного дискриминантного анализа (QDA);
* построение ROC-кривой.

*Модели*: логистическая регрессия, LDA, QDA.  
*Данные*: сгенерированный набор случаев диабета у женщин индейского племени Пима PimaIndiansDiabetes{mlbench}.В наборе 768 наблюдений и 9 показателей:

* pregnant - количество беременностей;
* glucose	- значения глюкозотолерантного теста;
* pressure -	 диастолическое давление;
* triceps	- Толщина створки кожи трицепсов;
* insulin	- инсулин в сыворотке крови;
* mass - индекс массы тела;
* pedigree	- функция родословной диабета;
* age	- возраст;
* diabetes - зависимая переменная,тест на диабет.(pos – наличие признака, neg – отсутствие)

# Пакеты:

```{r packages}
library('mlbench')
library('GGally')
library('MASS')
```

# Зададим ядро генератора случайных чисел и объём обучающей выборки.

```{r seed}
my.seed <- 123
train.percent <- 0.85
```

## Исходные данные: набор PimaIndiansDiabetes

```{r data}
data(PimaIndiansDiabetes)
head(PimaIndiansDiabetes)
str(PimaIndiansDiabetes)
ggpairs(PimaIndiansDiabetes)
```

## Отбираем наблюдения в обучающую выборку

```{r intrain}
set.seed(my.seed)
inTrain <- sample(seq_along(PimaIndiansDiabetes$diabetes),
                  nrow(PimaIndiansDiabetes) * train.percent)
df <- PimaIndiansDiabetes[inTrain, ] 
Факт <- df$diabetes
```

### Строим модели, чтобы спрогнозировать diabetes

##Логистическая регрессия

Из модели, изначально содержащей все исходные объяснящие переменные, были исключены следующие незначимые переменные: triceps, age. Таким образом получаем, что в окончательной модели параметры логистической регрессии значимы с вероятностью 0.95.

```{r logit}

model.logit <- glm(diabetes ~ pregnant+glucose+pressure+insulin+mass+pedigree, 
                   data = df, 
                   family = 'binomial')    
    
summary(model.logit)

# прогноз: вероятности принадлежности классу 'pos' (диабет)
p.logit <- predict(model.logit, df, type = 'response')
    
Прогноз <- factor(ifelse(p.logit > 0.5, 2, 1),
                  levels = c(1,2),
                  labels = c('neg','pos')) 
    
    

# матрица неточностей
conf.m <- table(Факт, Прогноз)
conf.m

# чувствительность
conf.m[2, 2] / sum(conf.m[2, ])
# специфичность
conf.m[1, 1] / sum(conf.m[1, ])
# верность
sum(diag(conf.m)) / sum(conf.m)  
    
```

## LDA

Отчёт по модели LDA содержит три раздела: априарные вероятности классов (Prior probabilities of groups), групповые средние объясняющих переменных (Group means) и коэффициенты линейной разделяющей границы (Coefficients of linear discriminants).
У этой модели чувствительность аналогичная.

```{r lda}

model.lda <- lda(diabetes ~ pregnant+glucose+pressure+insulin+mass+pedigree, 
                 data = df)
    
model.lda

# прогноз: вероятности принадлежности классу 'pos' (диабет)
p.lda <- predict(model.lda, df, 
                 type = 'response')
Прогноз <- factor(ifelse(p.lda$posterior[, 'pos'] > 0.5, 
                         2, 1),
                  levels = c(1, 2),
                  labels = c('neg', 'pos'))

# матрица неточностей
conf.m <- table(Факт, Прогноз)
conf.m

# чувствительность
conf.m[2, 2] / sum(conf.m[2, ])
# специфичность
conf.m[1, 1] / sum(conf.m[1, ])
# верность
sum(diag(conf.m)) / sum(conf.m)

```

## QDA

У этой модели чувствительность немного выше, чем у двух предыдущих моделей.

```{r qda}

model.qda <- qda(diabetes ~ pregnant+glucose+pressure+insulin+mass+pedigree, data = df)
    
model.qda

# прогноз: вероятности принадлежности классу 'pos' (диабет)
p.qda <- predict(model.qda, df, type = 'response')
Прогноз <- factor(ifelse(p.qda$posterior[, 'pos'] > 0.5, 
                         2, 1),
                  levels = c(1, 2),
                  labels = c('neg', 'pos'))

# матрица неточностей
conf.m <- table(Факт, Прогноз)
conf.m

# чувствительность
conf.m[2, 2] / sum(conf.m[2, ])
# специфичность
conf.m[1, 1] / sum(conf.m[1, ])
# верность
sum(diag(conf.m)) / sum(conf.m)
```

##ROC-кривая для QDA

Для начала построим график совместного изменения чувствительности и специфичности с изменением вероятности отсечения от 0 до 1 – ROC-кривую. Для примера возьмём модель QDA.

```{r roc}
x <- NULL    # для (1 - SPC)
y <- NULL    # для TPR

# заготовка под матрицу неточностей
tbl <- as.data.frame(matrix(rep(0, 4), 2, 2))
rownames(tbl) <- c('fact.neg', 'fact.pos')
colnames(tbl) <- c('predict.neg', 'predict.pos')

# цикл по вероятностям отсечения
for (p in seq(0, 1, length = 501)){
    # прогноз
    Прогноз <- factor(ifelse(p.qda$posterior[, 'pos'] > p, 
                               2, 1),
                        levels = c(1, 2),
                        labels = c('neg', 'pos'))
    # фрейм со сравнением факта и прогноза
    df.compare <- data.frame(Факт = Факт, Прогноз = Прогноз)
    # заполняем матрицу неточностей
    # TN
    tbl[1, 1] <- nrow(df.compare[df.compare$Факт == 'neg' & df.compare$Прогноз == 'neg', ])
        
    # TP
    tbl[2, 2] <- nrow(df.compare[df.compare$Факт == 'pos' & df.compare$Прогноз == 'pos', ])
        
    # FP
    tbl[1, 2] <- nrow(df.compare[df.compare$Факт == 'neg' & df.compare$Прогноз == 'pos', ])
    
    # FN
    tbl[2, 1] <- nrow(df.compare[df.compare$Факт == 'pos' & df.compare$Прогноз == 'neg', ])
        
    
    # считаем характеристики
    TPR <- tbl[2, 2] / sum(tbl[2, ])
    y <- c(y, TPR)
    SPC <- tbl[1, 1] / sum(tbl[1, ])
    x <- c(x, 1 - SPC)
}

# строим ROC-кривую
par(mar = c(5, 5, 1, 1))
# кривая
plot(x, y, 
     type = 'l', col = 'blue', lwd = 3,
     xlab = '(1 - SPC)', ylab = 'TPR', 
     xlim = c(0, 1), ylim = c(0, 1))
# прямая случайного классификатора
abline(a = 0, b = 1, lty = 3, lwd = 2)
```